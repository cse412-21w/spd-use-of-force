N <- 10000
pop <- rnorm(N, 1, 2)
pop.mean <- mean(pop)
pop.sd <- sd(pop)
pop.median <- median(pop)
c(pop.mean, pop.sd, pop.median)
hist(pop, breaks = 400, main = 'Histogram of Population')
n.trial <- 100
sample.size <- 90
CI <- matrix(nrow = n.trial, ncol = 2)
for(i in 1:n.trial) {
sample.trial <- sample(pop, sample.size)
CI[i, ] <- t.test(sample.trial)$conf.int[1:2]
}
count <- 0
for(i in 1:n.trial) {
if(CI[i, 1] <= pop.mean && CI[i,2] >= pop.mean) {
count <- count + 1
}
}
count
plot(c(1,1), CI[1, ], ylim = c(0,2), xlim = c(0, 101), ylab = "CI", xlab = '',
type = "1")
for(i in 2:n.trial) {
lines(c(i,i), CI[i, ])
}
abline(h = pop.mean, col = "red", lwd = 3)
plot(c(1,1), CI[1, ], ylim = c(0,2), xlim = c(0, 101), ylab = "CI", xlab = '')
plot(c(1,1), CI[1, ], ylim = c(0,2), xlim = c(0, 101), ylab = "CI", xlab = '', type = "1")
plot(c(1,1), CI[1, ], ylim = c(0, 2), xlim = c(0, 101), ylab = "CI", xlab = '', type = "l")
for(i in 2:n.trial) {
lines(c(i,i), CI[i, ])
}
abline(h = pop.mean, col = "red", lwd = 3)
##a) Write code to
##- read in that data set (it has a header),
##- plot brain weight (y) versus head size (x),
##- perform regression (to predict brain weight from head size),
##- draw the OLS fit on the scatterplot.
dat = read.table("http://sites.stat.washington.edu/people/marzban/390/winter21/brainhead_dat.txt",header=T)
x = dat[,3]
y = dat[,4]
plot(x,y)           # scatterplot
lm.1 = lm(y ~ x)    # regression
abline(lm.1, col=2) # draw the OLS line
##b) Write code to
##- compute SS_explained and SS_unexplained *By hand*, i.e. do NOT use the anova()
##function, but you may use lm() and predict(). Report the numerical answers.
SS_exp = sum((predict(lm.1) - mean(y))^2)   # 2184982
SS_unexp = sum( (y - predict(lm.1))^2 )     # 1232728
#c) Write code to show that SS_explained + SS_unexplained (from previous part)
#is equal to SS_Total. For example, you can report the value of
#SST - SS_explained - SS_unexplained. Note: It may not be exactly zero due to
#floating-point errors.
SST = sum((y - mean(y))^2)          # 3417710
SST - SS_exp - SS_unexp             # -7.683411e-09
#In a hw you just turned in, you showed that the cross-term in the ANOVA decomposition
#is identically zero. Let's confirm that numerically on the brainhead data. To that end,
#d) Write code to compute and report the cross-term.
sum( (predict(lm.1) - mean(y)) * (y - predict(lm.1)) )   # -3.929898e-09
#e) Write code to compute and report the cross-term, even if the model is a
#quadratic, i.e. constant + linear + quadratic.
lm.1 = lm(y ~ x + I(x^2) )
sum( (predict(lm.1) - mean(y)) * (y - predict(lm.1)) )   # -6.072682e-09
##Run the following code to
##- Read the qz6_dat.txt from the course website; it has a header.
##- Plot y versus x; note that x takes 10 distinct values, and there are many y values for each x. You should get the black circles in the figure shown.
dat = read.table("https://sites.stat.washington.edu/marzban/390/winter21/qz6_dat.txt",header=T)
x = dat[,1]
y = dat[,2]
plot(x,y)
##f) Write code to
##- find the sample mean of the y's for each value of x, using a for-loop.
##- Superimpose the 10 sample means on the previous plot, in red color, and make sure they are connected with red lines. You should get the red circles/lines in the figure shown.
ybar = numeric(10)
for(i in 1:10)
ybar[i] = mean(y[x==i])
points(c(1:10),ybar, type="b" col=2 )  # this or
lines(c(1:10),ybar, col=2 )            # this.
##g) Write code to
##- Fit a quadratic model (i.e. constant + linear + quadratic) to the x,y data.
##- Superimpose the fitted values on the previous plot, in green color, and make sure the dots are connected with green lines. You should get the green lines in the figure shown.
lm.1 = lm(y ~ x + I(x^2))
points(x,lm.1$fitted.value, type="b" col=3 )  # this or
lines(x,lm.1$fitted.value, col=3)             # this
##a) Write code to
##- read in that data set (it has a header),
##- plot brain weight (y) versus head size (x),
##- perform regression (to predict brain weight from head size),
##- draw the OLS fit on the scatterplot.
dat = read.table("http://sites.stat.washington.edu/people/marzban/390/winter21/brainhead_dat.txt",header=T)
x = dat[,3]
y = dat[,4]
plot(x,y)           # scatterplot
lm.1 = lm(y ~ x)    # regression
abline(lm.1, col=2) # draw the OLS line
##b) Write code to
##- compute SS_explained and SS_unexplained *By hand*, i.e. do NOT use the anova()
##function, but you may use lm() and predict(). Report the numerical answers.
SS_exp = sum((predict(lm.1) - mean(y))^2)   # 2184982
SS_unexp = sum( (y - predict(lm.1))^2 )     # 1232728
#c) Write code to show that SS_explained + SS_unexplained (from previous part)
#is equal to SS_Total. For example, you can report the value of
#SST - SS_explained - SS_unexplained. Note: It may not be exactly zero due to
#floating-point errors.
SST = sum((y - mean(y))^2)          # 3417710
SST - SS_exp - SS_unexp             # -7.683411e-09
#In a hw you just turned in, you showed that the cross-term in the ANOVA decomposition
#is identically zero. Let's confirm that numerically on the brainhead data. To that end,
#d) Write code to compute and report the cross-term.
sum( (predict(lm.1) - mean(y)) * (y - predict(lm.1)) )   # -3.929898e-09
#e) Write code to compute and report the cross-term, even if the model is a
#quadratic, i.e. constant + linear + quadratic.
lm.1 = lm(y ~ x + I(x^2) )
sum( (predict(lm.1) - mean(y)) * (y - predict(lm.1)) )   # -6.072682e-09
##Run the following code to
##- Read the qz6_dat.txt from the course website; it has a header.
##- Plot y versus x; note that x takes 10 distinct values, and there are many y values for each x. You should get the black circles in the figure shown.
dat = read.table("https://sites.stat.washington.edu/marzban/390/winter21/qz6_dat.txt",header=T)
x = dat[,1]
y = dat[,2]
plot(x,y)
##f) Write code to
##- find the sample mean of the y's for each value of x, using a for-loop.
##- Superimpose the 10 sample means on the previous plot, in red color, and make sure they are connected with red lines. You should get the red circles/lines in the figure shown.
ybar = numeric(10)
for(i in 1:10){
ybar[i] = mean(y[x==i])
}
points(c(1:10),ybar, type="b", col=2 )  # this or
lines(c(1:10),ybar, col=2 )            # this.
##g) Write code to
##- Fit a quadratic model (i.e. constant + linear + quadratic) to the x,y data.
##- Superimpose the fitted values on the previous plot, in green color, and make sure the dots are connected with green lines. You should get the green lines in the figure shown.
lm.1 = lm(y ~ x + I(x^2))
points(x,lm.1$fitted.value, type="b", col=3 )  # this or
lines(x,lm.1$fitted.value, col=3)             # this
conf.level = seq(0,1,length=100)
zstar = qnorm((1-conf.level)/2, lower.tail = F)
plot(conf.level, zstar)
pnorm(1.645, 0, 1, lower.tail = T)
pt(1.645, df = 5, lower.tail = T)
qnorm(0.05, 0, 1, lower.tail = T)
qt(0.05, df = 5, lower.tail = T)
pnorm(1.645, 0, 1, lower.tail = T)
pt(1.645, df = 5, lower.tail = T)
qnorm(0.05, 0, 1, lower.tail = T)
qt(0.05, df = 5, lower.tail = T)
pnorm(1.645, 0, 1, lower.tail = T)
pt(1.645, df = 5, lower.tail = F)
qnorm(0.05, 0, 1, lower.tail = T)
qt(0.05, df = 5, lower.tail = T)
pnorm(1.645, 0, 1, lower.tail = T)
pt(1.645, df = 5, lower.tail = F)
qnorm(0.05, 0, 1, lower.tail = T)
qt(0.05, df = 5, lower.tail = T)
pnorm(1.645, 0, 1, lower.tail = T)
pt(1.645, df = 5, lower.tail = F)
qnorm(0.05, 0, 1, lower.tail = T)
qt(0.05, df = 5, lower.tail = T)
x <- seq(-5, 5, 0.1)
y_1 <- dnorm(x, 0, 1)
y_2 <- dt(x, 2)
y_3 <- dt(x, 5)
plot(x, y_1, type = "l", ylab = 'y')
lines(x, y_2, col = 2)
line(x, y_3, col = 4)
legend('topleft', c('standard normal', 't with df = 2',
't with df = 4'), text.col = c(1, 2, 4), bty = 'n')
x <- seq(-5, 5, 0.1)
y_1 <- dnorm(x, 0, 1)
y_2 <- dt(x, 2)
y_3 <- dt(x, 4)
plot(x, y_1, type = "l", ylab = 'y')
lines(x, y_2, col = 2)
line(x, y_3, col = 4)
legend('topleft', c('standard normal', 't with df = 2',
't with df = 4'), text.col = c(1, 2, 4), bty = 'n')
x <- seq(-5, 5, 0.1)
y_1 <- dnorm(x, 0, 1)
y_2 <- dt(x, 2)
y_3 <- dt(x, 5)
plot(x, y_1, type = "l", ylab = 'y')
lines(x, y_2, col = 2)
lines(x, y_3, col = 4)
legend('topleft', c('standard normal', 't with df = 2',
't with df = 4'), text.col = c(1, 2, 4), bty = 'n')
dat <- read.table('https://sites.stat.washington.edu/marzban/390/winter21/attend_dat.txt'
, header = T)
attendance <- dat[, 1]
gender <- dat[, 2]
pa.boy <- attendance[gender == 0]
pa.girl <- attendance[gender == 1]
n.boys <- length(pa.boy)
n.girls <- length(pa.girl)
mean(pa.boy)
mean(pa.girl)
t.test(pa.boy)$conf.int[1:2]
t.test(pa.girl)$conf.int[1:2]
t.test(pa.boy, pa.girl, alternative = "two.sided")
data <- c(418, 421, 421, 422, 425, 427, 431, 434, 437, 439, 446, 447, 448, 453,
454, 463, 465)
boxplot(data)
boxplot(data, main = "Degree of Polymerization for Paper Specimens")
qqplot(data)
qqplot(data)
qqnorm(data)
qqnorm(data)
data <- c(418, 421, 421, 422, 425, 427, 431, 434, 437, 439, 446, 447, 448, 453,
454, 463, 465)
boxplot(data, main = "Degree of Polymerization for Paper Specimens")
qqnorm(data)
mean(data)
sd(data)
length(data)
ttest(data)
t.test(data)
qt(.05, 16)
qt(.025, 16)
qt(.975, 16)
boxplot(data, data2)
data2 <- c(429, 430, 430, 431, 436, 437, 440, 441, 445, 446, 447)
boxplot(data, data2)
mean(data2)
sd(data2)
length(data2)
x1 = c(-0.27, -0.14, 1.61, 0.09, 0.00, 2.07, 0.56, -1.67, -0.51, -0.54)
x2 = c(-0.32, 0.20, 1.93, 0.54, 0.75, 1.77, 0.84, -0.29, -0.33, 0.17)
plot(x1, x2)
mean(x1)
sd(x1)
length(x1)
mean(x2)
sd(x2)
length(x2)
qt(.995, 9)
qt(.05, 9)
qt(.005, 9)
qt(.975, 9)
y1 = c(-0.27, -0.14, 1.61, 0.09, 0.00, 2.07, 0.56, -1.67, -0.51, -0.54)
y2 = c( 0.20 , 0.54, -0.33, 1.93, -0.32, 1.77, 0.75, 0.17, -0.29, 0.84)
plot(y1, y2)
y1 = c(-0.27, -0.14, 1.61, 0.09, 0.00, 2.07, 0.56, -1.67, -0.51, -0.54)
y2 = c( 0.20 , 0.54, -0.33, 1.93, -0.32, 1.77, 0.75, 0.17, -0.29, 0.84)
mean(y1)
mean(y2)
sd(y1)
sd(y2)
length(y1)
length(y2)
obs <- c(2781, 2900, 3013, 2856, 2888)
mean(obs)
sd(obs)
length(obs)
qt(.975, 4)
weight <- c( 0.52, 0.65, 0.46, 0.50, 0.37)
mean(weight)
sd(weight)
length(weight)
qt(.05, 4)
help("t.test")
data <- read.table("https://sites.stat.washington.edu/marzban/390/winter21/presidents_dat.txt")
View(data)
height <- data[, 2]
test <- t.test(height, mu = 177.8, alternative = "greater")
test$p.value
qqnorm(height)
qqline(height)
qqnorm(height)
qqline(height, col = 2)
hist(height)
xbar_obs <- mean(height)
tobs <- (xbar_obs - 177.8) / (sd(height) / sqrt(length(height))
tobs <- (xbar_obs - 177.8) / (sd(height) / sqrt(length(height))
(xbar_obs - 177.8) / (sd(height) / sqrt(length(height))
xbar_obs <- mean(height)
n <- length(height)
s <- sd(height)
xbar_obs <- mean(height)
n <- as.numeric(length(height))
s <- sd(height)
t_obs <- (xbar_obs - 177.8) / (s / sqrt(n))
ptnorm(t_obs, mean = 177.8, sd = s/srt(n))
pt(t_obs, df = n-1)
p <- pt(t_obs, df = n-1, lower.tail = FALSE)
p
setwd("~/Documents")
# imports
library(rgdal)
library(dplyr)
library(dummies)
library(tidyverse)
library(RSocrata)
library(broom)
library(geojsonio)
setwd("~/GitHub/spd-use-of-force")
setwd("~/Documents/GitHub/spd-use-of-force")
beats <- readOGR('static/beats/SPD_BEATS_WGS84.shp')
census <- readOGR('static/census/A_Tract_Profile_ACS_5-year_2009-2013.shp')
uof <- as.data.frame(read.socrata('https://data.seattle.gov/resource/ppi5-g2bj.csv'))
pumas <- readOGR('static/pumas/cb_2018_53_puma10_500k.shp')
View(uof)
uof$occured_date_time <- as.Date(substr(uof$occured_date_time, 1, 10), format =
'%Y-%m-%d')
colnames(uof)[4] <- 'Date'
levels(uof$subject_race) <- c('Nat_Am', 'Asian', 'Black', 'Hisp_Lat', 'Pac_Isl',
'Race_NA', 'White')
uof$subject_race <- as.factor(uof$subject_race)
uof$incident_type <- as.factor(uof$incident_type)
levels(uof$incident_type) <- c('1', '2', '3', '4')
uof <- dummy.data.frame(data=uof, names=c('subject_race', 'subject_gender',
'incident_type'), sep='_')
uof$count <- 1
colnames(uof)[3:6] <- c('Type_1','Type_2','Type_3','Type_4')
colnames(uof)[13:22] <- c('Nat_Am', 'Asian', 'Black', 'Hisp_Lat', 'Pac_Isl',
'Race_NA', 'White', 'F', 'M', 'Gender_NA')
beats <- spTransform(beats, proj4string(census))
beats_df <- tidy(beats, id = 'objectid')
colnames(beats@data)[1] <- 'id'
beats_df <- left_join(beats_df, beats@data, by='id')
beats_df <- beats_df[1:8]
by_beat <- aggregate(cbind(Type_1, Type_2, Type_3, Type_4, Nat_Am, Asian, Black,
Hisp_Lat, Pac_Isl, Race_NA, White, F, M, Gender_NA,
count) ~ beat, data=uof, sum)
colnames(beats_df)[8] <- 'beat'
beats_df <- left_join(beats_df, by_beat, by='beat')
census <- cbind(census[1:3], census[6:8], census[10], census[12], census[14],
census[16], census[18], census[20], census[22], census[43:44],
census[48], census[50], census[54], census[56], census[78])
colnames(census@data) <- c('ID', 'GEOID', 'Tract_Name', 'Total_Pop', 'Median_Age',
'White', 'Black', 'NatAm', 'Asian', 'PacIsl',
'OtherRace', 'TwoPlusRace', 'HispLat', 'HSGrad',
'BachGrad', 'EngNotVWell', 'MedianHHIncome',
'Pop200PctBelowPov', 'PersonOfColor', 'Median_Gross_Rent')
census@data$Tract_Name <- substring(census@data$Tract_Name, 14,)
census_df <- census@data
pumas_df <- tidy(pumas, id = 'PUMACE10')
pumas@data <- pumas@data %>% mutate(id = row(pumas@data)[,1]-1)
pumas$id <- as.character(pumas$id)
pumas_df <- left_join(pumas_df, pumas@data, by='id')
pumas_df <- cbind(pumas_df[1:7], pumas_df$NAME10)
colnames(pumas_df)[8] <- 'name'
pumas_df <- pumas_df %>% filter(str_detect(name, 'Seattle'))
# keying both datasets by PUMA
NW_beats <- c('N1', 'N2', 'N3', 'J1', 'J2', 'J3', 'B1', 'B2', 'B3')
NE_beats <- c('L1', 'L2', 'L3', 'U1', 'U2', 'U3', 'H2')
Downtown_beats <- c('Q1', 'Q2', 'Q3', 'D1', 'D2', 'D3', 'M1', 'M2', 'M3', 'K1',
'E1', 'E3', 'K3')
SE_beats <- c('E2', 'G1', 'G2', 'G3', 'C1', 'C2', 'C3', 'R2', 'R3', 'H3', 'S2', 'S3')
W_beats <- c('K2', 'O1', 'O2', 'O3', 'R1', 'S1', 'W1', 'W2', 'W3', 'F1', 'F2', 'F3')
NW_tracts <- c('3', '4.01', '4.02', '5', '6', '13', '14', '15', '16', '17.01',
'17.02', '18', '27', '28', '29', '30', '31', '32', '33', '34',
'35', '36', '46', '47', '48', '49', '50', '51', '54')
NE_tracts <- c('1', '2', '7', '8', '9', '10', '11', '12', '19', '20', '21', '22',
'24', '25', '26', '38', '39', '40', '41', '42', '43.01', '43.02',
'44', '45', '52', '53.01', '53.02')
Downtown_tracts <- c('56', '57', '58.01', '58.02', '59', '60', '61', '66', '68',
'69', '70', '71', '72', '73', '74.01', '74.02', '80.01',
'80.02', '81', '82', '83', '84', '85', '91', '92')
SE_tracts <- c('62', '63', '64', '65', '75', '76', '77', '78', '86', '87', '88',
'89', '90', '95', '101', '102', '103', '111.01', '111.02', '118',
'119')
W_tracts <- c('93', '94', '96', '97.01', '97.02', '98', '99', '100.01', '100.02',
'104.01', '104.02', '105', '106', '107.01', '107.02', '108', '109',
'110.01', '110.02', '112', '113', '114.01', '114.02', '115', '116',
'117', '120', '121')
match_beat_PUMA <- function(s) {
if (s %in% NW_beats) {
return('NW')
} else if (s %in% NE_beats) {
return('NE')
} else if (s %in% Downtown_beats) {
return('Downtown')
} else if (s %in% SE_beats) {
return('SE')
} else if (s %in% W_beats) {
return('W')
} else {
return('')
}
}
match_tract_PUMA <- function(s) {
if (s %in% NW_tracts) {
return('NW')
} else if (s %in% NE_tracts) {
return('NE')
} else if (s %in% Downtown_tracts) {
return('Downtown')
} else if (s %in% SE_tracts) {
return('SE')
} else if (s %in% W_tracts) {
return('W')
} else {
return('')
}
}
by_beat$PUMA <- sapply(by_beat$beat, match_beat_PUMA)
beats@data$PUMA <- sapply(beats@data$beat, match_beat_PUMA)
census_df$PUMA <- sapply(census_df$Tract_Name, match_tract_PUMA)
# creating the final dataset
census_df <- census_df %>% filter(!(PUMA == ''))
by_puma <- aggregate(cbind(Total_Pop, White, Black, NatAm, Asian, PacIsl,
OtherRace, TwoPlusRace, HispLat, HSGrad, BachGrad,
EngNotVWell, Pop200PctBelowPov, PersonOfColor) ~ PUMA,
data = census_df, sum)
by_puma <- left_join(by_puma, aggregate(cbind(Median_Age, MedianHHIncome,
Median_Gross_Rent) ~ PUMA,
data = census_df, median))
by_beat <- left_join(by_beat, by_puma, by='PUMA')
colnames(by_beat) <- c('Beat', 'Type_1', 'Type_2', 'Type_3', 'Type_4', 'NatAm_uof',
'Asian_uof', 'Black_uof', 'HispLat_uof', 'PacIsl_uof',
'RaceNA_uof', 'White_uof', 'F_uof', 'M_uof', 'GenderNA_uof',
'Count_uof', 'PUMA', 'Total_Pop', 'White_pop', 'Black_pop',
'NatAm_pop', 'Asian_pop', 'PacIsl_pop', 'OtherRace_pop',
'TwoPlusRace_pop', 'HispLat_pop', 'HSGrad', 'BachGrad',
'EngNotVWell', 'Pop200PctBelowPov', 'PersonOfColor',
'Median_Age', 'Median_HHIncome', 'Median_GrossIncome')
by_puma <- left_join(by_puma, aggregate(cbind(Type_1, Type_2, Type_3, Type_4,
NatAm_uof, Asian_uof, Black_uof,
HispLat_uof, PacIsl_uof, RaceNA_uof,
White_uof, F_uof, M_uof, GenderNA_uof,
Count_uof) ~ PUMA, data = by_beat,
sum), by='PUMA')
by_date <- aggregate(cbind(Type_1, Type_2, Type_3, Type_4, Nat_Am, Asian,
Black, Hisp_Lat, Pac_Isl, Race_NA, White, count) ~ Date,
data = uof, sum)
View(by_date)
race <- c("White", "Black/African American","Native American", "Asian",
"Pacific Islander", "Hispanic / Latino", "Not Specified")
uof_count <- c(sum(by_beat$White_uof), sum(by_beat$Black_uof), sum(by_beat$NatAm_uof),
sum(by_beat$Asian_uof), sum(by_beat$PacIsl_uof), sum(by_beat$HispLat_uof),
sum(by_beat$RaceNA_uof))
uof_percent <- uof_count / total_uof_count
pop_count <- c(sum(by_puma$White), sum(by_puma$Black), sum(by_puma$NatAm),
sum(by_puma$Asian), sum(by_puma$PacIsl), sum(by_puma$HispLat), 0)
pop_percent <- pop_count / total_population
#combine columns into dataframe
minidata <- data.frame(race = race, uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
total_uof_count <- as.numeric(sum(by_beat$Type_1) + sum(by_beat$Type_2) +
sum(by_beat$Type_3) + sum(by_beat$Type_4))
total_population <- as.numeric(sum(by_puma$Total_Pop))
#creating columns
race <- c("White", "Black/African American","Native American", "Asian",
"Pacific Islander", "Hispanic / Latino", "Not Specified")
uof_count <- c(sum(by_beat$White_uof), sum(by_beat$Black_uof), sum(by_beat$NatAm_uof),
sum(by_beat$Asian_uof), sum(by_beat$PacIsl_uof), sum(by_beat$HispLat_uof),
sum(by_beat$RaceNA_uof))
uof_percent <- uof_count / total_uof_count
pop_count <- c(sum(by_puma$White), sum(by_puma$Black), sum(by_puma$NatAm),
sum(by_puma$Asian), sum(by_puma$PacIsl), sum(by_puma$HispLat), 0)
pop_percent <- pop_count / total_population
#combine columns into dataframe
minidata <- data.frame(race = race, uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
View(minidata)
minidata <- data.frame(uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
rownames(minidata) <- minidata$race
rownames(minidata) <- minidata$race
minidata <- data.frame(race = race, uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
rownames(minidata) <- minidata$race
minidata$race = NULL
minidata <- data.frame(uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
rownames(minidata) <- race
library(miscTools)
by_percent <- as.data.frame(t(race));
View(by_percent)
for(i in length(race)) {
by_percent[, i] <- c(uof_count[i]/total_uof_count, pop_count[i] / total_population)
}
View(by_percent)
by_percent <- data.frame(White = double(), Black = double(),
NatAm= double(), Asian = double(), PacIsl = double(),
HispLat = double(), RaceNA = double())
View(by_percent)
for(i in length(race)) {
by_percent[, i] <- c(uof_count[i]/total_uof_count, pop_count[i] / total_population)
}
default <- c(0, 0, 0)
by_percent <- data.frame(White = double(3), Black = double(3),
NatAm= double(3), Asian = double(3), PacIsl = double(3),
HispLat = double(3), RaceNA = double(3))
View(by_percent)
for(i in length(race)) {
by_percent[, i] <- c(uof_count[i]/total_uof_count, pop_count[i] / total_population,
uof_count[i]/total_uof_count - pop_count[i] / total_population)
}
c(uof_count[1]/total_uof_count, pop_count[1] / total_population,
uof_count[1]/total_uof_count - pop_count[1] / total_population)
by_percent[, 1]
for(i in as.numeric(length(race))) {
by_percent[, i] <- c(uof_count[i]/total_uof_count, pop_count[i] / total_population,
uof_count[i]/total_uof_count - pop_count[i] / total_population)
}
by_percent[, 1] <- c(uof_count[1]/total_uof_count, pop_count[1] / total_population,
+                        uof_count[1]/total_uof_count - pop_count[1] / total_population)
for(i in 1:7) {
by_percent[, i] <- c(uof_count[i]/total_uof_count, pop_count[i] / total_population,
uof_count[i]/total_uof_count - pop_count[i] / total_population)
}
`colnames<-`(uof_count, pop_count, difference)
rownames(by_percent)<- c(uof_count, pop_count, difference)
rownames(by_percent)<- c("uof_count", "pop_count", "difference")
by_race <- data.frame(uof_percent = uof_percent, pop_percent = pop_percent,
difference = uof_percent - pop_percent)
rownames(by_race) <- race
View(by_race)
View(by_puma)
write.csv(by_percent, 'static/by_percent.csv')
